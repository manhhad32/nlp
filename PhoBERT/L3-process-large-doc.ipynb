{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B1: load mode, encode doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Khởi tạo tokenizer và mô hình PhoBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "model = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "\n",
    "# Hàm để chia tài liệu thành các đoạn nhỏ hơn\n",
    "def chunk_document(text, max_length=100):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    chunks = [tokens[i:i + max_length] for i in range(0, len(tokens), max_length)]\n",
    "    return chunks\n",
    "\n",
    "# Hàm để mã hóa đoạn văn bản\n",
    "def encode_chunk(chunk):\n",
    "    # Nếu chunk trống, trả về một vector không (zero vector) hoặc bỏ qua\n",
    "    if len(chunk) == 0:\n",
    "        return None\n",
    "    inputs = tokenizer(\" \".join(chunk), return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    chunk_vector = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return chunk_vector\n",
    "\n",
    "# Hàm để mã hóa toàn bộ tài liệu\n",
    "def encode_long_text(text):\n",
    "    chunks = chunk_document(text)\n",
    "    chunk_vectors = []\n",
    "    for chunk in chunks:\n",
    "        chunk_vector = encode_chunk(chunk)\n",
    "        if chunk_vector is not None:  # Chỉ thêm các vector hợp lệ\n",
    "            chunk_vectors.append(chunk_vector)\n",
    "    return chunk_vectors\n",
    "\n",
    "def load_documents_from_directory(directory):\n",
    "    print('Loading documents from vnexpress directory')\n",
    "    docs = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        print('Đọc dữ liệu từ file: [{}]...'.format(file_name))\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        lines = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as fi:\n",
    "            # reade file acording lines.\n",
    "            for line in fi:\n",
    "                # change to lower character and remove space at head/tail of line.\n",
    "                line = line.lower().strip()\n",
    "                # add to list\n",
    "                lines.append(line)\n",
    "        # create doc as text inline.\n",
    "        doc = \" \".join(lines)\n",
    "        # clean, remove some spec word in head/tail.\n",
    "        re.sub('\\W+',' ', doc)\n",
    "        docs.append(doc) \n",
    "    print('End documents from vnexpress directory')\n",
    "    return docs\n",
    "\n",
    "# Ví dụ danh sách các tài liệu dài\n",
    "#documents = [\"sạt lở đất ở Tà Xùa, Sơn La ngày 10/8. Ảnh: Ban chỉ huy quân sự huyện Bắc YênTrung tâm Dự báo Khí tượng Thủy văn quốc gia nhận định từ nay đến ngày 17/8, miền Bắc sẽ mưa lớn, cao điểm mưa 60-120 mm, có nơi trên 250 mm tập trung từ 11 đến 13/8. Lượng mưa lớn, tập trung vào chiều tối và đêm, trên phạm vi hẹp (ở không gian cấp tỉnh) nên khả năng cao gây lũ quét, sạt lở đất, ngập úng tại các khu vực trũng thấp, đặc biệt ở các tỉnh vùng núi phía Bắc.Trang Accuweather của Mỹ dự báo Hà Nội tuần tới phổ biến 26-32 độ C, riêng thứ năm nhiệt độ cao nhất trong ngày lên 34 độ. Điểm cao trên 1.500 m so với mực nước biển như Sa Pa (Lào Cai) nhiệt độ trong tuần 17-26 độ C.Miền Trung các tỉnh Thanh Hóa, Nghệ An chịu ảnh hưởng của rãnh áp thấp ở phía bắc nên đêm nay và chiều tối mai có mưa rào, giông. Vùng nắng nóng thu hẹp vào các tỉnh Hà Tĩnh - Bình Thuận với nhiệt độ cao nhất ngày phổ biến 35-37 độ, có nơi trên 37 độ C.Nam Bộ và Tây Nguyên từ nay đến 13/8 có mưa rào, giông về chiều tối. Các ngày 14-17/8, gió mùa tây nam suy yếu, mưa tiếp tục giảm.Nhiệt độ cao nhất ở Nam Bộ phổ biến 32-34 độ, Tây Nguyên 29-32 độ C. Từ ngày 14/7, nhiệt độ Nam Bộ tăng lên 33-35 độ, miền Đông Nam Bộ có nắng nóng cục bộ, Tây Nguyên 30-33 độ C.Miền Bắc vừa trải qua gần một tuần nắng nóng nhưng các tỉnh miền núi vẫn mưa rào, giông về chiều tối và đêm. Độ ẩm trong đất ở nhiều khu vực đã bão hòa nên nguy cơ sạt lở đất rất cao.Bộ Nông nghiệp và Phát triển nông thôn hôm qua tiếp tục yêu cầu UBND các tỉnh miền Bắc theo dõi diễn biến thời tiết, tổ chức kiểm tra khu vực có nguy cơ lũ quét, sạt lở. Các địa phương tổ chức canh gác ở ngầm tràn, khu vực đã hoặc có nguy cơ sạt lở, không cho người qua lại; sẵn sàng lực lượng, phương tiện cứu hộ, cứu nạn khi có yêu cầu.\", \n",
    "#             \"trước đó gần một ngày, CAS ra phán quyết chấp thuận vụ kiện của COSR về tranh cãi liên quan đến HC đồng thể dục dụng cụ biểu diễn sàn nữ. Số điểm ban đầu của Chiles cần được giữ nguyên là 13,666 điểm, vì thế Barbosu với 13,700 điểm nhận được HC đồng.Chung kết biểu diễn sàn đã diễn ra hôm 5/8, khi Chiles thi cuối và được trọng tài chấm 13,666 điểm. Trong khi Barbosu reo mừng, đội thể dục dụng cụ Mỹ khiếu nại lên các trọng tài, vì cho rằng họ đã chấm nhầm điểm độ khó của nữ VĐV 23 tuổi.Trong thể dục dụng cụ, mỗi phần thi của VĐV thường có điểm độ khó được xác định dựa trên các loại động tác, và điểm kỹ thuật dựa theo đánh giá của trọng tài. Điểm độ khó của Chiles đã được quy ước là 5,9 nhưng trọng tài mắc sai lầm nên chỉ chấm 5,8.Trọng tài sau đó chấp nhận khiếu nại của Mỹ, chấm lại điểm độ khó của Chiles từ\",\n",
    "#             ]\n",
    "documents = load_documents_from_directory('/content/data-nlp/')\n",
    "\n",
    "\n",
    "# Mã hóa và lưu trữ các vector biểu diễn\n",
    "document_vectors = []\n",
    "for doc in documents:\n",
    "    vectors = encode_long_text(doc)\n",
    "    document_vectors.append([v.tolist() for v in vectors])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 2: Mã Hóa Câu Truy Vấn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Câu truy vấn\n",
    "query = \"Trước thảm họa khiến khoảng 150 người thiệt mạng trong đám đông\"\n",
    "\n",
    "# Mã hóa câu truy vấn\n",
    "query_tokens = tokenizer.tokenize(query)\n",
    "query_inputs = tokenizer(\" \".join(query_tokens), return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "with torch.no_grad():\n",
    "    query_outputs = model(**query_inputs)\n",
    "query_vector = query_outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 3: Tính Toán Độ Tương Đồng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tính độ tương đồng cosine\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Tính toán độ tương đồng giữa câu truy vấn và các đoạn của mỗi tài liệu\n",
    "similarities = []\n",
    "for doc_vectors in document_vectors:\n",
    "    doc_similarities = [cosine_similarity(query_vector, vec) for vec in doc_vectors]\n",
    "    max_similarity = max(doc_similarities)\n",
    "    similarities.append(max_similarity)\n",
    "\n",
    "# Sắp xếp các tài liệu theo độ tương đồng giảm dần\n",
    "sorted_docs = sorted(zip(documents, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# In ra các tài liệu có độ tương đồng cao nhất\n",
    "result_doc = []\n",
    "for doc, similarity in sorted_docs[:30]:  # Top 10 tài liệu tương đồng nhất\n",
    "    result_doc.append(f\"Tài liệu: {doc[:100]}... (độ tương đồng: {similarity:.4f})\")\n",
    "    print(f\"Tài liệu: {doc[:100]}... (độ tương đồng: {similarity:.4f})\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
